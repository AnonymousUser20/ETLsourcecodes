{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EXTRACTION AND TRANSFORMATION OF CONFERENCE DATA**\n",
        "\n",
        "This notebook is split into 2 sections.\n",
        "- Data Extraction :\n",
        "This section contains a list of methods to extract data from multiple data storage formats, to fetch data of accepted papers for major conferences in Ai/ML/NLP/CSV.\n",
        "- Data Transformation :\n",
        "This section contains a list of methods to transform data from multiple data storage formats, to a uniform storage format, i.e., csv."
      ],
      "metadata": {
        "id": "JCZvUdUioBdC"
      },
      "id": "JCZvUdUioBdC"
    },
    {
      "cell_type": "markdown",
      "id": "bf99959e-1981-4049-970d-88d690b0f76e",
      "metadata": {
        "id": "bf99959e-1981-4049-970d-88d690b0f76e"
      },
      "source": [
        "## IMPORT MODULES (always run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YdKiZAUJW62l",
      "metadata": {
        "id": "YdKiZAUJW62l"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99146a43-d9a0-428d-9eac-ecdda819a9fa",
      "metadata": {
        "id": "99146a43-d9a0-428d-9eac-ecdda819a9fa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U--d1_puB56N",
      "metadata": {
        "id": "U--d1_puB56N"
      },
      "source": [
        "# **DATA EXTRACTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the following conference, the data extraction is done from the HTML tags of static websites, using the BeautifulSoup library. The year-wise data of Paper titles, Paper Abstract, List of Authors and their affiliations (if available) are collected."
      ],
      "metadata": {
        "id": "rv-_4Wb93vLu"
      },
      "id": "rv-_4Wb93vLu"
    },
    {
      "cell_type": "markdown",
      "id": "TIQsq2Huibk5",
      "metadata": {
        "id": "TIQsq2Huibk5"
      },
      "source": [
        "## COLING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hPDgcpYnihhn",
      "metadata": {
        "id": "hPDgcpYnihhn"
      },
      "outputs": [],
      "source": [
        "year = 2024 #[2023, 2024, 2025]\n",
        "url = f\"https://lrec-coling-{year}.org/list-of-accepted-papers/\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IRtAO9cfi7Zv",
      "metadata": {
        "id": "IRtAO9cfi7Zv"
      },
      "outputs": [],
      "source": [
        "\n",
        "papers = []\n",
        "\n",
        "rows = soup.find_all(\"tr\")\n",
        "\n",
        "for row in rows:\n",
        "    cells = row.find_all('td')\n",
        "    authors = None\n",
        "    title = None\n",
        "\n",
        "    for cell in cells:\n",
        "        cell_id = cell.get('data-cell-id', '')\n",
        "        if re.match(r'^B\\d+$', cell_id):  # B followed by digits\n",
        "            authors = cell.get_text(strip=True)\n",
        "        elif re.match(r'^C\\d+$', cell_id):  # C followed by digits\n",
        "            title = cell.get_text(strip=True)\n",
        "\n",
        "    if authors and title:\n",
        "        papers.append({f\"Title\": title, f\"Authors\": authors})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M8Tdojn6nJMR",
      "metadata": {
        "id": "M8Tdojn6nJMR"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(papers)\n",
        "df.to_csv(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/COLING/2024/coling_2024_papers.csv\", index=False, encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VxyNV0W7Kb5c",
      "metadata": {
        "id": "VxyNV0W7Kb5c"
      },
      "source": [
        "## KDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JPyPN68pJYIl",
      "metadata": {
        "id": "JPyPN68pJYIl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def kdd_extraction(year, url):\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status()\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/KDD/KDD{year}papers.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "      writer = csv.writer(csvfile)\n",
        "      writer.writerow([\"Title\", \"Authors_Institutes\"])\n",
        "\n",
        "      for h5 in soup.find_all('h5', class_ = \"wp-block-heading has-text-align-left\"):\n",
        "        title = h5.get_text(strip = True)\n",
        "        p_tag = h5.find_next(\"p\")\n",
        "        authors_institutes = p_tag.get_text(strip=True)\n",
        "        writer.writerow([title, authors_institutes])\n",
        "def main ():\n",
        "  years = [2023, 2024, 2025]\n",
        "  url2023 = f'https://kdd.org/kdd{years[0]}/research-track-papers/index.html'\n",
        "  url2024 = f'https://kdd{years[1]}.kdd.org/research-track-papers/'\n",
        "  url2025 = f'https://kdd{years[2]}.kdd.org/research-track-papers/'\n",
        "  urls = [url2023, url2024, url2025]\n",
        "  for year, url in zip(years, urls):\n",
        "    kdd_extraction(year, url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3KTLDMkG44fs",
      "metadata": {
        "id": "3KTLDMkG44fs"
      },
      "source": [
        "## ACL (different website layout for each year)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3kqrpPZY3Don",
      "metadata": {
        "id": "3kqrpPZY3Don"
      },
      "outputs": [],
      "source": [
        "year = 2023\n",
        "url = f'https://{year}.aclweb.org/program/accepted_main_conference/#long-papers'\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ACL/ACL{year}papers.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Authors\"])\n",
        "\n",
        "    for p in soup.find_all('p'):\n",
        "      title = p.find(\"strong\").get_text(strip = True)\n",
        "      authors = p.find('em').get_text(strip=True)\n",
        "      writer.writerow([title, authors])\n",
        "\n",
        "year = 2024\n",
        "url = f'https://{year}.aclweb.org/program/main_conference_papers/'\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ACL/ACL{year}papers.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Authors\"])\n",
        "\n",
        "    for li in soup.find_all('li'):\n",
        "\n",
        "        title_tag = li.find(\"strong\")\n",
        "        authors_tag = li.find(\"em\")\n",
        "\n",
        "        title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
        "        authors = authors_tag.get_text(strip=True) if authors_tag else \"\"\n",
        "\n",
        "        writer.writerow([title, authors])\n",
        "\n",
        "year = 2025\n",
        "url = f'https://{year}.aclweb.org/program/main_papers/'\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ACL/ACL{year}papers.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Authors\"])\n",
        "\n",
        "    for li in soup.find_all('li'):\n",
        "\n",
        "        title_tag = li.find(\"strong\")\n",
        "        authors_tag = li.find(\"em\")\n",
        "\n",
        "        title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
        "        authors = authors_tag.get_text(strip=True) if authors_tag else \"\"\n",
        "\n",
        "        writer.writerow([title, authors])\n",
        "\n",
        "df = pd.read_csv(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ACL/ACL{year}papers.csv\")\n",
        "df.dropna(how=\"all\", inplace=True)\n",
        "df.to_csv(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ACL/ACL{year}papers.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KeGddRCbGj0r",
      "metadata": {
        "id": "KeGddRCbGj0r"
      },
      "source": [
        "## CVPR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CVPR conference website is dynamic, that renders data in the frontend from database stored as json in the backend."
      ],
      "metadata": {
        "id": "k8Q1fDGekBLY"
      },
      "id": "k8Q1fDGekBLY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U3yTcdFZGxNx",
      "metadata": {
        "id": "U3yTcdFZGxNx"
      },
      "outputs": [],
      "source": [
        "def cvpr_extraction(year):\n",
        "  url = f\"https://cvpr.thecvf.com/static/virtual/data/cvpr-{year}-orals-posters.json\"\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status()\n",
        "  data = response.json()\n",
        "  with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/CVPR/CVPR{year}.json\", 'w') as file:\n",
        "        json.dump(data['results'],file)\n",
        "def main():\n",
        "  years = [2023, 2024, 2025]\n",
        "  for year in years:\n",
        "    cvpr_extraction(year)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b49567-f7d0-4bb6-adb1-af217791ef4d",
      "metadata": {
        "id": "78b49567-f7d0-4bb6-adb1-af217791ef4d"
      },
      "source": [
        "## AAAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3vyH1sXTCYzF",
      "metadata": {
        "id": "3vyH1sXTCYzF"
      },
      "source": [
        "AAAI websites host their database of accepted papers, in the form of pdf, which encountered strructuring issues on converting to csv. This problem has been handled by accessing the website : https://papercopilot.com."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def AAAI_extraction(year):\n",
        "  url = f\"https://raw.githubusercontent.com/papercopilot/paperlists/main/aaai/aaai{year}.json\"\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status()\n",
        "  data = response.json()\n",
        "  df = pd.DataFrame(data)\n",
        "  df.to_csv(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/AAAI/AAAI{year}.csv\")\n",
        "\n",
        "def AAAI_cleaning(year):\n",
        "  df = pd.read_csv(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/AAAI/AAAI{year}.csv\")\n",
        "  df = df[[\"title\", \"abstract\", \"author\", \"aff\"]]\n",
        "  df = df.rename(columns={'title': 'Title', 'abstract': 'Abstract', 'author': 'Authors', 'aff': 'Institutions'})\n",
        "  df.to_csv(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/AAAI/AAAI{year}.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "def main ():\n",
        "  years = [2023, 2024, 2025]\n",
        "  for year in years:\n",
        "    AAAI_extraction(year)\n",
        "    AAAI_cleaning(year)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "p5KcZa0ut76o"
      },
      "id": "p5KcZa0ut76o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c44ee2cf-8379-423e-ae1e-84269ecc852c",
      "metadata": {
        "id": "c44ee2cf-8379-423e-ae1e-84269ecc852c"
      },
      "source": [
        "# OpenReview Script"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenReview does not host their database in the form of HTML tags. The website renders content dynamically from their database, using JavaScript. This database is publicly available, which can be accessed from specific endpoint API URls. On hitting these API URLs, the data can be viewed in the form of JSON. The same approach has been scripted in Python to load and extract the JSON.\n",
        "\n",
        "The following conferences conduct their Review process on OpenReview\n",
        "- ICLR\n",
        "- NeurIPS\n",
        "- ICML (starting from 2025)\n",
        "\n",
        "The modularized code for ICLR is illustrated in this notebook, the same process has been repeeated for ICML (2023-2025) and NeurIPS (2023-2024)."
      ],
      "metadata": {
        "id": "TIOSvXCD_NaB"
      },
      "id": "TIOSvXCD_NaB"
    },
    {
      "cell_type": "markdown",
      "id": "0eb8e72b-881b-4494-8ed3-5d114345a6e9",
      "metadata": {
        "id": "0eb8e72b-881b-4494-8ed3-5d114345a6e9"
      },
      "source": [
        "# ICLR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5194634e-1dba-4ffa-96da-38581b40e62d",
      "metadata": {
        "id": "5194634e-1dba-4ffa-96da-38581b40e62d"
      },
      "source": [
        "## ICLR 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0d9e6d-2a83-43b3-adbc-650fcdae4def",
      "metadata": {
        "id": "4e0d9e6d-2a83-43b3-adbc-650fcdae4def"
      },
      "source": [
        "### ICLR 2023 TOP 5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e499111b-bae2-43b3-b5d6-6fe29f0b0ef2",
      "metadata": {
        "id": "e499111b-bae2-43b3-b5d6-6fe29f0b0ef2"
      },
      "outputs": [],
      "source": [
        "def ICLR2023_top5_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "    offset = 25*(i)\n",
        "    url = f'https://api.openreview.net/notes?content.venue=ICLR+2023+notable+top+5%25&details=replyCount&offset={offset}&limit=25&invitation=ICLR.cc%2F2023%2FConference%2F-%2FBlind_Submission'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    year = 2023\n",
        "    with open (f\"ICLR{year}_top5.json\", 'w') as file: #modify filename while running cell to prevent over writing on the same file\n",
        "        json.dump(data, file)\n",
        "\n",
        "def main():\n",
        "  tabs = 5 #please check website\n",
        "  ICLR2023_top5_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f7c8b3-dd97-4f61-9a06-9726d8dae974",
      "metadata": {
        "id": "33f7c8b3-dd97-4f61-9a06-9726d8dae974"
      },
      "source": [
        "### ICLR 2023 Top 25%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95db0f9e-20e9-49b9-9b9e-ad6e441b4fa4",
      "metadata": {
        "id": "95db0f9e-20e9-49b9-9b9e-ad6e441b4fa4"
      },
      "outputs": [],
      "source": [
        "def ICLR2023_top25_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "      offset = 25*(i)\n",
        "      url = f'https://api.openreview.net/notes?content.venue=ICLR+2023+notable+top+25%25&details=replyCount&offset={offset}&limit=25&invitation=ICLR.cc%2F2023%2FConference%2F-%2FBlind_Submission'\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      with open(f\"ICLR2023_top25_page{i}.json\", 'w') as file:\n",
        "          json.dump(data,file)\n",
        "\n",
        "def main():\n",
        "  tabs = 12 #please check the website\n",
        "  ICLR2023_top25_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1d7bab8-441c-4d37-adc2-a2625541add0",
      "metadata": {
        "id": "a1d7bab8-441c-4d37-adc2-a2625541add0"
      },
      "source": [
        "### ICLR 2023 Poster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca54a47-c804-4cf1-a36f-2b501e8424b9",
      "metadata": {
        "id": "dca54a47-c804-4cf1-a36f-2b501e8424b9"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 50):\n",
        "    offset = 25*(i-1)\n",
        "    url = f'https://api.openreview.net/notes?content.venue=ICLR+2023+poster&details=replyCount&offset={offset}&limit=25&invitation=ICLR.cc%2F2023%2FConference%2F-%2FBlind_Submission'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    with open(f\"ICLR 2023/Poster/ICLR2023_Posters_page{i}.json\", 'w') as file:\n",
        "        json.dump(data,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4ffb5a1-5e22-4704-9939-56a1510ef445",
      "metadata": {
        "id": "e4ffb5a1-5e22-4704-9939-56a1510ef445"
      },
      "source": [
        "### ICLR 2023 Submitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8f21a8-720f-4ed0-a9d7-a0daa7e2ed19",
      "metadata": {
        "id": "0e8f21a8-720f-4ed0-a9d7-a0daa7e2ed19"
      },
      "outputs": [],
      "source": [
        "def ICLR2023_submitted_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "      offset = 25*(i-1)\n",
        "      url = f'https://api.openreview.net/notes?content.venue=Submitted+to+ICLR+2023&details=replyCount&offset={offset}&limit=25&invitation=ICLR.cc%2F2023%2FConference%2F-%2FBlind_Submission'\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      with open(f\"ICLR 2023/Submitted/ICLR2023_Submitted_page{i}.json\", 'w') as file:\n",
        "          json.dump(data,file)\n",
        "\n",
        "def main ():\n",
        "  tabs = 90\n",
        "  ICLR2023_submitted_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50fd7d44-f326-4a57-ac8e-51ae61ca18ca",
      "metadata": {
        "id": "50fd7d44-f326-4a57-ac8e-51ae61ca18ca"
      },
      "source": [
        "### ICLR 2023 Desk Rejected/Withdrawn Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a642b6-3bf7-46ae-91c9-e1a030d6349d",
      "metadata": {
        "id": "61a642b6-3bf7-46ae-91c9-e1a030d6349d"
      },
      "outputs": [],
      "source": [
        "def ICLR2023_rejected_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "      offset = 25*(i-1)\n",
        "      url = f'https://api.openreview.net/notes?details=replyCount%2Cinvitation%2Coriginal&offset={offset}&limit=25&invitation=ICLR.cc%2F2023%2FConference%2F-%2FWithdrawn_Submission'\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      with open(f\"ICLR 2023/Withdrawn_Rejected/ICLR2023_withdrawn_page{i}.json\", 'w') as file:\n",
        "          json.dump(data,file)\n",
        "\n",
        "def main ():\n",
        "  tabs = 48\n",
        "  ICLR2023_rejected_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vuhzg9LajGo-",
      "metadata": {
        "id": "Vuhzg9LajGo-"
      },
      "source": [
        "## ICLR 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YjOaJ7vqjp1i",
      "metadata": {
        "id": "YjOaJ7vqjp1i"
      },
      "source": [
        "### ICLR 2024 (accepted oral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d0ed26-582b-4828-bc2e-c85cc3018b24",
      "metadata": {
        "id": "60d0ed26-582b-4828-bc2e-c85cc3018b24"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 5):\n",
        "    offset = 25*(i-1)\n",
        "    url = f'https://api2.openreview.net/notes?content.venue=ICLR%202024%20oral&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2024%2FConference&limit=25&offset={offset}'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    with open(f\"ICLR 2024/accepted(oral)/ICLR2024_oral_page{i}.json\", 'w') as file:\n",
        "        json.dump(data,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TdqaE1B1myqp",
      "metadata": {
        "id": "TdqaE1B1myqp"
      },
      "source": [
        "### ICLR 2024 (accepted spotlight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QEsPnLn_kWch",
      "metadata": {
        "id": "QEsPnLn_kWch"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 16):\n",
        "    offset = 25*(i-1)\n",
        "    url = f'https://api2.openreview.net/notes?content.venue=ICLR%202024%20spotlight&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2024%2FConference&limit=25&offset={offset}'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    with open(f\"ICLR 2024/accepted(spotlight)/ICLR2024_spotlight_page{i}.json\", 'w') as file:\n",
        "        json.dump(data,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pCCEu_k4uAjm",
      "metadata": {
        "id": "pCCEu_k4uAjm"
      },
      "source": [
        "### ICLR 2024 (accepted poster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wl33sgCCp0yc",
      "metadata": {
        "id": "Wl33sgCCp0yc"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 74):\n",
        "    offset = 25*(i-1)\n",
        "    url = f'https://api2.openreview.net/notes?content.venue=ICLR%202024%20poster&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2024%2FConference&limit=25&offset={offset}'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    with open(f\"ICLR 2024/accepted(poster)/ICLR2024_poster_page{i}.json\", 'w') as file:\n",
        "        json.dump(data,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27Vwtrrnyaa7",
      "metadata": {
        "id": "27Vwtrrnyaa7"
      },
      "source": [
        "### ICLR 2024 (reject)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZtKzFF9_xs20",
      "metadata": {
        "id": "ZtKzFF9_xs20"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 139):\n",
        "    offset = 25*(i-1)\n",
        "    url = f'https://api2.openreview.net/notes?content.venue=Submitted%20to%20ICLR%202024&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2024%2FConference&limit=25&offset={offset}'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    with open(f\"ICLR 2024/reject/ICLR2024_reject_page{i}.json\", 'w') as file:\n",
        "        json.dump(data,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "APHo8cMo07WP",
      "metadata": {
        "id": "APHo8cMo07WP"
      },
      "source": [
        "### ICLR 2024 (withdrawn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aO6OGEiyzoI7",
      "metadata": {
        "id": "aO6OGEiyzoI7"
      },
      "outputs": [],
      "source": [
        "for i in range(61, 68):\n",
        "    offset = 25*(i-1)\n",
        "    url = f'https://api2.openreview.net/notes?content.venueid=ICLR.cc%2F2024%2FConference%2FWithdrawn_Submission&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2024%2FConference&limit=25&offset={offset}'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    with open(f\"ICLR 2024/withdrawn/ICLR2024_withdrawn_page{i}.json\", 'w') as file:\n",
        "        json.dump(data,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wLNS-3bf2bLx",
      "metadata": {
        "id": "wLNS-3bf2bLx"
      },
      "source": [
        "### ICLR 2024 (Desk Rejected Submissions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WCBLzgb21o2n",
      "metadata": {
        "id": "WCBLzgb21o2n"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 4):\n",
        "    offset = 25*(i-1)\n",
        "    url = f'https://api2.openreview.net/notes?content.venueid=ICLR.cc%2F2024%2FConference%2FDesk_Rejected_Submission&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2024%2FConference&limit=25&offset={offset}'\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.json()\n",
        "    with open(f\"ICLR 2024/desk_rejected/ICLR2024_desk_rejected_page{i}.json\", 'w') as file:\n",
        "        json.dump(data,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZxvW3O126H5B",
      "metadata": {
        "id": "ZxvW3O126H5B"
      },
      "source": [
        "## ICLR 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o224F-N772j4",
      "metadata": {
        "id": "o224F-N772j4"
      },
      "source": [
        "### ICLR 2025 (accepted oral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MRlhGXBP4D9w",
      "metadata": {
        "id": "MRlhGXBP4D9w"
      },
      "outputs": [],
      "source": [
        "def ICLR2025_oral_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "      offset = 25*(i-1)\n",
        "      url = f'https://api2.openreview.net/notes?content.venue=ICLR%202025%20Oral&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2025%2FConference&limit=25&offset={offset}'\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2025/accepted(oral)/ICLR2025_oral_page{i}.json\", 'w') as file:\n",
        "          json.dump(data,file)\n",
        "\n",
        "def main():\n",
        "  tabs = 10\n",
        "  ICLR2025_oral_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bQfDTIH7_S9",
      "metadata": {
        "id": "1bQfDTIH7_S9"
      },
      "source": [
        "### ICLR 2025 (accepted spotlight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Dn1pcDH7eI9",
      "metadata": {
        "id": "1Dn1pcDH7eI9"
      },
      "outputs": [],
      "source": [
        "def ICLR2025_spotlight_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "      offset = 25*(i)\n",
        "      url = f'https://api2.openreview.net/notes?content.venue=ICLR%202025%20Spotlight&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2025%2FConference&limit=25&offset={offset}'\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2025/accepted(spotlight)/ICLR2025_spotlight_page{i}.json\", 'w') as file:\n",
        "          json.dump(data,file)\n",
        "\n",
        "def main():\n",
        "  tabs = 17\n",
        "  ICLR2025_spotlight_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zGqDnFYh-0O7",
      "metadata": {
        "id": "zGqDnFYh-0O7"
      },
      "source": [
        "### ICLR 2025 (reject)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hAk5U45Z8IzC",
      "metadata": {
        "id": "hAk5U45Z8IzC"
      },
      "outputs": [],
      "source": [
        "def ICLR2025_reject_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "      offset = 25*(i)\n",
        "      url = f'https://api2.openreview.net/notes?content.venue=Submitted%20to%20ICLR%202025&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2025%2FConference&limit=25&offset={offset}'\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2025/reject/ICLR2025_reject_page{i}.json\", 'w') as file:\n",
        "          json.dump(data,file)\n",
        "\n",
        "def main():\n",
        "  tabs = 198\n",
        "  ICLR2025_reject_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "twdzGxeGBHM4",
      "metadata": {
        "id": "twdzGxeGBHM4"
      },
      "source": [
        "### ICLR 2025 (withdrawn submissions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9_a2Mvx--D3y",
      "metadata": {
        "id": "9_a2Mvx--D3y"
      },
      "outputs": [],
      "source": [
        "def ICLR2025_withdrawn_extraction(tabs):\n",
        "  for i in range(tabs):\n",
        "      offset = 25*(i)\n",
        "      url = f'https://api2.openreview.net/notes?content.venueid=ICLR.cc%2F2025%2FConference%2FWithdrawn_Submission&details=replyCount%2Cpresentation%2Cwritable&domain=ICLR.cc%2F2025%2FConference&limit=25&offset={offset}'\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2025/withdrawn/ICLR2025_withdrawn_page{i}.json\", 'w') as file:\n",
        "          json.dump(data,file)\n",
        "\n",
        "def main():\n",
        "  tabs = 121\n",
        "  ICLR2025_withdrawn_extraction(tabs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r4WkLWkGSmnw",
      "metadata": {
        "id": "r4WkLWkGSmnw"
      },
      "source": [
        "# Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reviews have been collected for the conferences in 2023. The Review data are fetched from the OpenReview website, from endpoint API URLs in similar way. The paper ids of previously extracted jsons have been used to collected review data of every paper."
      ],
      "metadata": {
        "id": "ECeMh50yiBs7"
      },
      "id": "ECeMh50yiBs7"
    },
    {
      "cell_type": "markdown",
      "id": "SLy02VeWP12I",
      "metadata": {
        "id": "SLy02VeWP12I"
      },
      "source": [
        "## ICLR 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qSgWC_T3XwKn",
      "metadata": {
        "id": "qSgWC_T3XwKn"
      },
      "outputs": [],
      "source": [
        "def ICLR_reviews(category):\n",
        "  directory = Path(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2023/{category}\")\n",
        "  json_count = len(list(directory.glob(\"*.json\")))\n",
        "  for i in range(1, json_count+1):\n",
        "    #change json name with every category update\n",
        "    with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2023/{category}/ICLR2023_{category}_page{i}.json\", 'r') as file:\n",
        "      content = json.load(file)\n",
        "      for note in content['notes']:\n",
        "        id = note['id']\n",
        "        url = f\"https://api.openreview.net/notes?forum={id}&trash=true&details=replyCount%2Cwritable%2Crevisions%2Coriginal%2Coverwriting%2Cinvitation%2Ctags&limit=1000&offset=0\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        #to avoid error 429 : too many requests in short time\n",
        "        if response.status_code == 429:\n",
        "            print(\"Rate limit hit. Waiting...\")\n",
        "            time.sleep(10)  # Wait 10 seconds before retry\n",
        "            response = requests.get(url)\n",
        "\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2023/Reviews/{category}/Reviews{id}.json\", 'w') as file:\n",
        "            json.dump(data, file)\n",
        "        time.sleep(1) #to avoid error 429 : too many requests in short time\n",
        "\n",
        "def main():\n",
        "  categories = [\"Poster\", \"Submitted\", \"Withdrawn_Rejected\", \"top25\", \"top_5\"]\n",
        "  for category in categories:\n",
        "    ICLR_reviews(category)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZPVY7lc_fVpn",
      "metadata": {
        "id": "ZPVY7lc_fVpn"
      },
      "source": [
        "## NeurIPS 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vBNMcC9GfXRk",
      "metadata": {
        "id": "vBNMcC9GfXRk"
      },
      "outputs": [],
      "source": [
        "def NeurIPS_reviews(category):\n",
        "  category = \"accept(oral)\" #[\"accept(oral)\", \"accept(poster)\", \"accept(spotlight)\", \"reject\"]\n",
        "  directory = Path(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/NeurIPS/NeurIPS 2023/{category}\")\n",
        "  json_count = len(list(directory.glob(\"*.json\")))\n",
        "  for i in range(1, json_count+1):\n",
        "    #change json name with every category update\n",
        "    with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/NeurIPS/NeurIPS 2023/{category}/NeurIPS2023_oral_page{i}.json\", 'r') as file:\n",
        "      content = json.load(file)\n",
        "      for note in content['notes']:\n",
        "        id = note['id']\n",
        "        url = f\"https://api2.openreview.net/notes?count=true&details=writable%2Csignatures%2Cinvitation%2Cpresentation%2Ctags&domain=NeurIPS.cc%2F2023%2FConference&forum={id}&limit=1000&trash=true\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        #to avoid error 429 : too many requests in short time\n",
        "        if response.status_code == 429:\n",
        "            print(\"Rate limit hit. Waiting...\")\n",
        "            time.sleep(10)  # Wait 10 seconds before retry\n",
        "            response = requests.get(url)\n",
        "\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/NeurIPS/NeurIPS 2023/Reviews/{category}/Reviews{id}.json\", 'w') as file:\n",
        "            json.dump(data, file)\n",
        "        time.sleep(1) #to avoid error 429 : too many requests in short time\n",
        "\n",
        "def main():\n",
        "  categories = [\"accept(oral)\", \"accept(poster)\", \"accept(spotlight)\", \"reject\"]\n",
        "  for category in categories:\n",
        "    NeurIPS_reviews(category)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ruUJaVrAjosi",
      "metadata": {
        "id": "ruUJaVrAjosi"
      },
      "source": [
        "# **DATA TRANSFORMATION** (json to csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The extracted data is converted to uniform data storage format, i.e., csv."
      ],
      "metadata": {
        "id": "Vh64PlUinzoL"
      },
      "id": "Vh64PlUinzoL"
    },
    {
      "cell_type": "markdown",
      "id": "SlRQWDMLjzwZ",
      "metadata": {
        "id": "SlRQWDMLjzwZ"
      },
      "source": [
        "## CVPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zPXw_PeMjsbg",
      "metadata": {
        "id": "zPXw_PeMjsbg"
      },
      "outputs": [],
      "source": [
        "def cvpr_transform(year):\n",
        "  url = f\"https://cvpr.thecvf.com/static/virtual/data/cvpr-{year}-orals-posters.json\"\n",
        "  with open (f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/CVPR/CVPR{year}.csv\", \"w\", newline = \"\", encoding = \"utf-8\") as f:\n",
        "      writer=csv.writer(f)\n",
        "      writer.writerow([\"Title\",\"Authors\",\"Institutes\"])\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      data = response.json()\n",
        "      data = data['results']\n",
        "      for paper in data:\n",
        "        title = paper['name']\n",
        "        au = []\n",
        "        ins = []\n",
        "        for author in paper['authors']:\n",
        "          au.append(author['fullname'])\n",
        "          ins.append(author['institution'])\n",
        "        writer.writerow([title, au, ins])\n",
        "def main():\n",
        "  years = [2023, 2024, 2025]\n",
        "  for year in years:\n",
        "    cvpr_transform(year)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ClOBAZ4UsfIi",
      "metadata": {
        "id": "ClOBAZ4UsfIi"
      },
      "source": [
        "## ICLR, ICML, NeurIPS (2023-2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MduuNIR6Ccp9",
      "metadata": {
        "id": "MduuNIR6Ccp9"
      },
      "outputs": [],
      "source": [
        "def transformation(conference, year, category):\n",
        "directory = Path(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/{conference}/{conference} {year}/{category}\")\n",
        "json_count = len(list(directory.glob(\"*.json\")))\n",
        "with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/{conference}/{conference} {year}/{category}/{category}.csv\", 'w') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow([\"Title\", \"Authors\", \"Institutes\"])\n",
        "  for i in range(1, json_count+1):\n",
        "    #change json name with every category update\n",
        "    with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/{conference}/{conference} {year}/{category}/ICLR{year}_{category}s_page{i}.json\", 'r') as file:\n",
        "      all_content = json.load(file)\n",
        "      for note in all_content['notes']:\n",
        "        title = note['content']['title']\n",
        "        au = []\n",
        "        ins = []\n",
        "        for author in note['content']['authors']:\n",
        "          au.append(author)\n",
        "        for author_id in note['content']['authorids']:\n",
        "          url = f\"https://openreview.net/profile?id={author_id}\"\n",
        "          response = requests.get(url)\n",
        "          response.raise_for_status()\n",
        "          soup = BeautifulSoup(response.text, 'html.parser')\n",
        "          institution = soup.find('div', class_=\"institution\")\n",
        "          if institution:\n",
        "            ins.append(institution.get_text(strip = True))\n",
        "          else:\n",
        "            ins.append(\"Not Found\")\n",
        "\n",
        "          #to avoid error 429 : too many requests in short time\n",
        "          if response.status_code == 429:\n",
        "              print(\"Rate limit hit. Waiting...\")\n",
        "              time.sleep(10)  # Wait 10 seconds before retry\n",
        "              response = requests.get(url)\n",
        "\n",
        "          response.raise_for_status()\n",
        "        writer.writerow([title, au, ins])\n",
        "\n",
        "        time.sleep(1) #to avoid error 429 : too many requests in short time\n",
        "\n",
        "def main():\n",
        "  conferences = [\"ICLR\", \"NeurIPS\", \"ICML\"]\n",
        "  years = [2023, 2024, 2025]\n",
        "  categories = [\"Poster\", \"Submitted\", \"Withdrawn_Rejected\", \"top25\", \"top_5\"] #change as per requirement\n",
        "  for conference in conferences:\n",
        "    for year in years:\n",
        "      for category in categories:\n",
        "        transformation(conference, year, category)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6iDrlKnSdXrI",
      "metadata": {
        "id": "6iDrlKnSdXrI"
      },
      "source": [
        "## Review Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ICLR"
      ],
      "metadata": {
        "id": "h4vAvChlnNJD"
      },
      "id": "h4vAvChlnNJD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s9Bo5xAqdcqW",
      "metadata": {
        "id": "s9Bo5xAqdcqW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def iclr_review_transform(category):\n",
        "  directory = Path(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2023/Reviews/{category}\")\n",
        "  json_files = list(directory.glob(\"*.json\"))\n",
        "  with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/ICLR/ICLR 2023/Reviews/{category}/A_{category}_Reviews.csv\", 'w', newline='') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"Title\", \"Rounds of Discussion\", \"Average Rating\", \"Average Confidence\"])\n",
        "    for json_file in json_files:\n",
        "      with open(json_file, 'r') as f_json:\n",
        "        all_content = json.load(f_json)\n",
        "\n",
        "        title = \"Unknown Title\"\n",
        "        rounds = 0\n",
        "        if all_content and 'notes' in all_content and len(all_content['notes']) > 0:\n",
        "            threads = len(all_content['notes'])\n",
        "\n",
        "            # Robust title extraction\n",
        "            submission_note = None\n",
        "            for note in all_content['notes']:\n",
        "                if 'id' in note and 'forum' in note and note['id'] == note['forum'] and 'content' in note and 'title' in note['content']:\n",
        "                    submission_note = note\n",
        "                    break\n",
        "            if submission_note:\n",
        "                title_content = submission_note['content']['title']\n",
        "                if isinstance(title_content, dict) and 'value' in title_content:\n",
        "                    title = title_content['value']\n",
        "                elif isinstance(title_content, str):\n",
        "                    title = title_content\n",
        "            elif len(all_content['notes']) > 0 and 'content' in all_content['notes'][0] and 'title' in all_content['notes'][0]['content']:\n",
        "                title_content = all_content['notes'][0]['content']['title']\n",
        "                if isinstance(title_content, dict) and 'value' in title_content:\n",
        "                    title = title_content['value']\n",
        "                elif isinstance(title_content, str):\n",
        "                    title = title_content\n",
        "\n",
        "\n",
        "            for i in range(1, threads):\n",
        "              current_note = all_content['notes'][i]\n",
        "              previous_note = all_content['notes'][i-1]\n",
        "\n",
        "              # Check if 'signatures' exists and is not empty before accessing index 0\n",
        "              if 'signatures' in current_note and current_note['signatures'] and \\\n",
        "                'signatures' in previous_note and previous_note['signatures']:\n",
        "                  if \"Reviewer\" in current_note['signatures'][0]:\n",
        "                    if \"Authors\" in previous_note['signatures'][0]:\n",
        "                      rounds += 1\n",
        "\n",
        "        disc = rounds\n",
        "\n",
        "        conf_values = []\n",
        "        rating_values = []\n",
        "        for note in all_content['notes']:\n",
        "          if 'confidence' in note['content']:\n",
        "            conf_values.append(int(note['content']['confidence'][0]))\n",
        "          if 'recommendation' in note['content']:\n",
        "            rating_values.append(int(note['content']['recommendation'][0]))\n",
        "\n",
        "        avg_conf = sum(conf_values) / len(conf_values) if len(conf_values) > 0 else 0\n",
        "        avg_rating = sum(rating_values) / len(rating_values) if len(rating_values) > 0 else 0\n",
        "\n",
        "        writer.writerow([title, disc, avg_rating, avg_conf])\n",
        "\n",
        "def main():\n",
        "  categories = [\"Poster\", \"Submitted\", \"Withdrawn_Rejected\", \"top25\", \"top_5\"]\n",
        "  for category in categories:\n",
        "    iclr_review_transform(category)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PMGbWUeQp6I5",
      "metadata": {
        "id": "PMGbWUeQp6I5"
      },
      "source": [
        "### NeurIPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FSxQTU8CpLIw",
      "metadata": {
        "id": "FSxQTU8CpLIw"
      },
      "outputs": [],
      "source": [
        "def cvpr_review_transform(category):\n",
        "  directory = Path(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/NeurIPS/NeurIPS 2023/Reviews/{category}\")\n",
        "  json_files = list(directory.glob(\"*.json\"))\n",
        "  with open(f\"/content/drive/MyDrive/Project Progress/Generated Dataset/Conferences/NeurIPS/NeurIPS 2023/Reviews/{category}/A_{category}_Reviews.csv\", 'w', newline='') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"Title\", \"Rounds of Discussion\", \"Average Rating\", \"Average Confidence\"])\n",
        "    for json_file in json_files:\n",
        "      with open(json_file, 'r') as f_json:\n",
        "        all_content = json.load(f_json)\n",
        "\n",
        "        title = \"Unknown Title\"\n",
        "        rounds = 0\n",
        "        if all_content and 'notes' in all_content and len(all_content['notes']) > 0:\n",
        "            threads = len(all_content['notes']) # <--- Added this line\n",
        "            submission_note = None\n",
        "            for note in all_content['notes']:\n",
        "                if 'id' in note and 'forum' in note and note['id'] == note['forum'] and 'content' in note and 'title' in note['content']:\n",
        "                    submission_note = note\n",
        "                    break\n",
        "            if submission_note:\n",
        "                title_content = submission_note['content']['title']\n",
        "                if isinstance(title_content, dict) and 'value' in title_content:\n",
        "                    title = title_content['value']\n",
        "                elif isinstance(title_content, str):\n",
        "                    title = title_content\n",
        "            elif len(all_content['notes']) > 0 and 'content' in all_content['notes'][0] and 'title' in all_content['notes'][0]['content']:\n",
        "                title_content = all_content['notes'][0]['content']['title']\n",
        "                if isinstance(title_content, dict) and 'value' in title_content:\n",
        "                    title = title_content['value']\n",
        "                elif isinstance(title_content, str):\n",
        "                    title = title_content\n",
        "            for i in range(1, threads):\n",
        "              current_note = all_content['notes'][i]\n",
        "              previous_note = all_content['notes'][i-1]\n",
        "\n",
        "              # Check if 'signatures' exists and is not empty before accessing index 0\n",
        "              if 'signatures' in current_note and current_note['signatures'] and \\\n",
        "                'signatures' in previous_note and previous_note['signatures']:\n",
        "                  if \"Reviewer\" in current_note['signatures'][0]:\n",
        "                    if \"Authors\" in previous_note['signatures'][0]:\n",
        "                      rounds += 1\n",
        "\n",
        "        disc = rounds\n",
        "\n",
        "        conf_values = []\n",
        "        rating_values = []\n",
        "        for note in all_content['notes']:\n",
        "          if 'content' in note and 'confidence' in note['content']:\n",
        "            # Robustly extract confidence value\n",
        "            confidence_data = note['content']['confidence']\n",
        "            if isinstance(confidence_data, dict) and 'value' in confidence_data and confidence_data['value']:\n",
        "                conf_values.append(int(confidence_data['value'][0]))\n",
        "            elif isinstance(confidence_data, list) and confidence_data:\n",
        "                conf_values.append(int(confidence_data[0]))\n",
        "          if 'content' in note and 'rating' in note['content']:\n",
        "            # Robustly extract rating value\n",
        "            rating_data = note['content']['rating']\n",
        "            if isinstance(rating_data, dict) and 'value' in rating_data and rating_data['value']:\n",
        "                rating_values.append(int(rating_data['value'][0]))\n",
        "            elif isinstance(rating_data, list) and rating_data:\n",
        "                rating_values.append(int(rating_data[0]))\n",
        "\n",
        "        avg_conf = sum(conf_values) / len(conf_values) if len(conf_values) > 0 else 0\n",
        "        avg_rating = sum(rating_values) / len(rating_values) if len(rating_values) > 0 else 0\n",
        "\n",
        "        writer.writerow([title, disc, avg_rating, avg_conf])\n",
        "\n",
        "def main():\n",
        "  categories = [\"accept(oral)\", \"accept(poster)\", \"accept(spotlight)\", \"reject\"]\n",
        "  for category in categories:\n",
        "    cvpr_review_transform(category)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "U--d1_puB56N",
        "0eb8e72b-881b-4494-8ed3-5d114345a6e9",
        "nT5XPHZrXVgw",
        "WkUWcEFvvNem",
        "lthN8eqhJT2l",
        "OsdT_DRH3B33",
        "KeGddRCbGj0r",
        "r4WkLWkGSmnw",
        "SLy02VeWP12I",
        "fViklxKJc3RR",
        "SlRQWDMLjzwZ",
        "ClOBAZ4UsfIi",
        "0HFpNZasT4lG",
        "02gaj3cHaAYq",
        "Xf94-FlhsmSY",
        "e58rM5w0c5lJ",
        "1Is9Y6padoMZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}